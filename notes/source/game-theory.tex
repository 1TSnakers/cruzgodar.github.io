\documentclass{article}

\usepackage[utf8]{inputenc}
\usepackage{amsmath}
\usepackage{amsfonts}
\usepackage{amssymb}
\usepackage[margin=1in]{geometry}

\usepackage{graphicx}
\graphicspath{{graphics/}}

\usepackage{hyperref}

\usepackage{scalerel}

\usepackage{xcolor}

\usepackage{stmaryrd}

\usepackage{MnSymbol}

\usepackage{mdframed}

\usepackage{titlesec}

\usepackage{blkarray}

\titleformat{\section}
{\normalfont \Large \bfseries \centering}{\Roman{section} --- }{0pt}{}




\definecolor{DefGreen}{rgb}{0,0.5,0}
\definecolor{TheoremOrange}{rgb}{0.88,0.6,0.08}
\definecolor{LemmaYellow}{rgb}{1,1,0}
\definecolor{CorollaryBlue}{rgb}{0,0.29,0.77}
\definecolor{ProofPurple}{rgb}{0.58,0,1}
\definecolor{AxiomRed}{rgb}{1,0,0}



\usepackage{amsthm}

\newtheoremstyle{colontheorem}
	{0in}                    	% Space above
	{.15in}                   	% Space below
	{\normalfont}      		    % Body font
	{}                          % Indent amount
	{\bfseries}                 % Theorem head font
	{:}                         % Punctuation after theorem head
	{.5em}                      % Space after theorem head
	{}							% Theorem head spec (can be left empty, meaning ‘normal’)
	
\theoremstyle{colontheorem}

\newtheorem{theorem}{Theorem}[section]
\newtheorem{proposition}[theorem]{Proposition}
\newtheorem{definition}[theorem]{Definition}
\newtheorem{axiom}[theorem]{Axiom}

\newtheorem{lemma}{Lemma}[theorem]
\newtheorem{corollary}{Corollary}[theorem]

\newtheorem{exercise}{Exercise}[section]




\newcommand{\Span}{\textnormal{span}}
\newcommand{\Null}{\textnormal{null }}
\newcommand{\Range}{\textnormal{range }}
\newcommand{\T}{^\textnormal{T}}
\newcommand{\Sub}{\textnormal{sub }}



\newenvironment{Theorem}
{
	\begin{mdframed}[backgroundcolor=TheoremOrange!10]
	\begin{theorem}
}
{
	\end{theorem}
	\end{mdframed}
	
	\vspace{.15in}
}

\newenvironment{Proposition}
{
	\begin{mdframed}[backgroundcolor=TheoremOrange!10]
	\begin{proposition}
}
{
	\end{proposition}
	\end{mdframed}
	
	\vspace{.15in}
}

\newenvironment{Def}
{
	\begin{mdframed}[backgroundcolor=DefGreen!10]
	\begin{definition}
}
{
	\end{definition}
	\end{mdframed}
	
	\vspace{.15in}
}

\newenvironment{Axiom}
{
	\begin{mdframed}[backgroundcolor=AxiomRed!10]
	\begin{axiom}
}
{
	\end{axiom}
	\end{mdframed}
	
	\vspace{.15in}
}

\newenvironment{Lemma}
{
	\begin{mdframed}[backgroundcolor=LemmaYellow!10]
	\begin{lemma}
}
{
	\end{lemma}
	\end{mdframed}
	
	\vspace{.03in}
}

\newenvironment{Corollary}
{
	\vspace{-.035in}
	
	\begin{mdframed}[backgroundcolor=CorollaryBlue!10]
	\begin{corollary}
}
{
	\end{corollary}
	\end{mdframed}
	
	\vspace{.09in}
}

\newenvironment{Proof}
{
	\begin{mdframed}[backgroundcolor=ProofPurple!10]
	\textbf{Proof:}%
}
{
	\end{mdframed}
	
	\vspace{.085in}
}

\newenvironment{Example}
{
	\begin{mdframed}
	\textbf{Example:}%
}
{
	\end{mdframed}
	
	\vspace{.15in}
}



\setlength{\parindent}{0pt}




\begin{document}

\vspace*{.5in}

\begin{center}
	\Huge Game Theory Notes\\
	
	\vspace{.25in}
	
	\Large Cruz Godar\\
	
	\vspace{.25in}
	
	\normalsize Math 437\\
	
	Professor Mendes\\
	
	Cal Poly, Spring 2017
\end{center}

\vspace{.5in}





\begin{center}
	\section{Matrix Games}
	\vspace{.1in}
\end{center}



\begin{Def}
	
	A \textbf{game} is a situation in which players choose a single option, called a \textbf{strategy}, secretly, then are rewarded based on their choice of strategy and their opponents'.
	
\end{Def}



\begin{Def}
	
	A game is \textbf{finite} if both players have a finite number of strategies to choose from.
	
\end{Def}



\begin{Def}
	
	Let $S_1, ..., S_n$ be the sets of strategies for players $1, ..., n$. The \textbf{payoff} to player $i$ is a function $P_i : S_1 \times \cdots \times S_n \longrightarrow \mathbb{R}$.
	
\end{Def}



\begin{Def}
	
	A game is \textbf{zero-sum} if $P_1(s_1, ..., s_n) + \cdots + P_n(s_1, ..., s_n) = 0$ for all $s_i \in S_i$.
	
\end{Def}



\begin{Def}
	
	A \textbf{matrix game} is a finite, two-player, zero-sum game with the possible payoffs to player $1$ given by the entries in an $m \times n$ matrix $A$. The row player and column player each secretly and independently select a row $i$ and column $j$, respectively. The payoff to the row player is $a_{ij}$ and the payoff to the column player is $-a_{ij}$.
	
\end{Def}



\begin{Example}
	%
	Rock-Paper-Scissors:
	
	$$
	A = \begin{bmatrix}
	
	0 & -1 & 1\\
	1 & 0 & -1\\
	-1 & 1 & 0
	
	\end{bmatrix},
	$$
	
	where rock is the first row/column, paper is the second, and scissors is the third.
	
\end{Example}



\begin{Def}
	
	Row $i$ \textbf{dominates} row $j$ if $\mathbf{e_i}\T A \geq \mathbf{e_j}\T A$, where $\mathbf{e_j}\T = [0\ \cdots\ 0\ 1\ 0\ \cdots\ 0]$ with the $1$ in the $i$th position --- that is, row $i$ dominates row $j$ is every element of row $i$ is greater than or equal to the corresponding element in row $j$. Similarly, column $i$ dominates column $j$ if $A \mathbf{e_i} \leq A \mathbf{e_j}$. Notice that a player never needs to play a dominated row or column.
	
\end{Def}



\begin{Def}
	
	An entry $a_{ij}$ in a matrix game $A$ is a \textbf{saddle point} if $a_{ij}$ is both a row minimum and a column maximum. Notice that if $a_{ij}$ is a saddle point, then the row player can announce she is playing row $i$ and the column player that he is playing column $j$, and neither will gain an advantage with the knowledge.
	
\end{Def}



\begin{Proposition}
	
	All saddle points of a matrix have the same value.
	
	\begin{Proof}
		%
		Let $a$ and $b$ be saddle points of $A$. Then
		
		$$
		\begin{bmatrix}
		
		& | & & | &\\
		\textnormal{---} & a & \textnormal{---} & c & \textnormal{---}\\
		& | & & | &\\
		\textnormal{---} & d & \textnormal{---} & b & \textnormal{---}\\
		& | & & | &\\
		
		\end{bmatrix}.
		$$
		
		Since $a$ and $b$ are saddle points, $a \leq c \leq b \leq d \leq a$, so $a = b$.
		
	\end{Proof}
	
\end{Proposition}



\begin{Def}
	
	A \textbf{probability vector} is a vector $\mathbf{x} \in \mathbb{R}^n$ such that $\mathbf{x}\T \mathbf{1} = 1$ and $\mathbf{x} \geq \mathbf{0}$.
	
\end{Def}



\begin{Def}
	
	Let $A$ be an $m \times n$ matrix game. A \textbf{solution} to $A$ is an ordered triple $(\mathbf{x}, \mathbf{y}, v)$, where $\mathbf{x}$ and $\mathbf{y}$ are probability vectors and $v \in \mathbb{R}$ such that $\mathbf{x}\T A \geq v \mathbf{1}\T$ and $A \mathbf{y} \leq v \mathbf{1}$. The number $v$ is called the \textbf{value} of the game.
	
\end{Def}



\begin{Theorem}
	
	\textbf{(Minimax)} Every matrix game has a solution.
	
\end{Theorem}



\begin{Proposition}
	
	The value of a matrix game is unique,.
	
	\begin{Proof}
		%
		Suppose $(\mathbf{x}_1, \mathbf{y}_1, v_1)$ and $(\mathbf{x}_2, \mathbf{y}_2, v_2$ are solutions to $A$. Then $A \mathbf{y}_1 \leq v_1 \mathbf{1}$, so $\mathbf{x}_2\T A \mathbf{y}_1 \leq \mathbf{x}_2\T v_1 \mathbf{1}$, and $\mathbf{x}_2\T A \geq v_2 \mathbf{1}\T$, so $\mathbf{x}_2\T A \mathbf{y}_1 \geq v_2 \mathbf{1}\T \mathbf{y}_1$. Thus $v_2 = v_2 \mathbf{1}\T \mathbf{y}_1 \leq \mathbf{x}_2\T A \mathbf{y}_1 \leq \mathbf{x}_2\T v_1 \mathbf{1} = v_1$, so $v_2 \leq v_1$, and similarly, $v_1 \leq v_2$, so $v_1 = v_2$.
		
	\end{Proof}
	
\end{Proposition}



\begin{Theorem}
	
	\textbf{(A Method to Solve $\mathbf{2 \times 2}$ Matrix Games)}
	
	\begin{enumerate}
		
		\item If there is a saddle point, then a solution is for the row and column players to play the row and column of the saddle point. Then the value is the value of the saddle point.
		
		\item Otherwise, let $\mathbf{x} = [p\ \ \ 1-p]\T$ and $\mathbf{y} = [q\ \ \ 1-q]\T$. Set the two entries of $\mathbf{x}\T A$ equal to solve for $p$ and the two entries of $A \mathbf{y}$ equal to solve for $q$. Let $v = \mathbf{x}\T A = A \mathbf{y}$. Then a solution is $(\mathbf{x}, \mathbf{y}, v)$.
		
	\end{enumerate}
	
\end{Theorem}



\begin{Theorem}
	
	\textbf{(Equilibrium)} If row $i$ is used with positive probability in an optimal strategy $\mathbf{x}$, then the $i$th row of $A\mathbf{y}$ is the $v$, the value of $A$.
	
	\begin{Proof}
		%
		If the $i$th row of $A\mathbf{y}$ were not $v$, then the row player would earn an expected payoff of less than $v$ by playing row $i$ and would therefore never do so. $\lightning$
		
	\end{Proof}
	
\end{Theorem}



\begin{Proposition}
	
	Let $(\mathbf{x}, \mathbf{y}, v)$ be a solution to $A$. Then $(\mathbf{x}, \mathbf{y}, v + c)$ is a solution to $A + c1$.
	
	\begin{Proof}
		%
		We have $\mathbf{x}\T (A + c1) = \mathbf{x}\T A + \mathbf{x}\T c 1 \geq v \mathbf{1}\T + c \mathbf{1}\T = (v + c) \mathbf{1}\T$, and similarly, $(A + c1) \mathbf{y} \leq \mathbf{1}$.
		
	\end{Proof}
	
\end{Proposition}



\begin{Def}
	
	A matrix game is \textbf{completely mixed} if every optimal strategy $(\mathbf{x}, \mathbf{y}, v)$ satisfies $\mathbf{x} \geq \mathbf{0}$ and $\mathbf{y} \geq \mathbf{0}$.
	
\end{Def}



\begin{Theorem}
	
	Let $A$ be a matrix game such that $A$ is invertible, $\mathbf{1}\T A^{-1} \mathbf{1} \neq 0$, the value of $A$ is nonzero, and $A$ is completely mixed. Then there is a unique solution to $A$, given by $\mathbf{x}\T = v \mathbf{1}\T A^{-1}$, $\mathbf{y} = v A^{-1} \mathbf{1}$, and $v = \frac{1}{\mathbf{1}\T A^{-1} \mathbf{1}}$.
	
\end{Theorem}



\begin{Def}
	
	A set $C \subseteq \mathbb{R}^n$ is \textbf{convex} if $\lambda \mathbf{x} + (1 - \lambda) \mathbf{y} \in C$ for all $\mathbf{x}, \mathbf{y} \in C$ and all $\lambda \in [0, 1]$.
	
\end{Def}



\begin{Theorem}
	
	The set of optimal row strategies for a matrix game is convex.
	
\end{Theorem}



\begin{Def}
	
	A \textbf{convex combination} of vectors $\mathbf{x}_1, ..., \mathbf{x}_n$ is a vector of the form $\lambda_1 \mathbf{x}_1 + \cdots + \lambda_n \mathbf{x}_n$, where each $\lambda_i \geq 0$ and $\lambda_1 + \cdots  + \lambda_n = 1$.
	
\end{Def}



\begin{Def}
	
	A vector $\mathbf{x}$ in a convex set $C$ is \textbf{extreme} if $\mathbf{x}$ cannot be expressed as a convex combination of other vectors in $C$.
	
\end{Def}



\begin{Theorem}
	
	\textbf{(Shapley-Snow)} Let $A$ be a matrix game with value $v \neq 0$. Then $\mathbf{x}$ and $\mathbf{y}$ are extreme optimal solutions to $A$ if and only if there is an $r \times r$ submatrix $S$ of $A$ such that $S^{-1}$ exists, $v = \frac{1}{\mathbf{1}\T S^{-1} \mathbf{1}}$, $(\mathbf{x}')\T = v \mathbf{1}\T S^{-1}$, and $\mathbf{y}' = v S^{-1} \mathbf{1}$, where $\mathbf{x}'$ and $\mathbf{y}'$ are $\mathbf{x}$ and $\mathbf{y}$ with any $0$s removed.
	
\end{Theorem}



\begin{Theorem}
	
	\textbf{(A Method to Solve any Matrix Game)} Let $A$ be a matrix game.
	
	\begin{enumerate}
		
		\item Find all invertible submatrices $S$ for which $\mathbf{1}\T S^{-1} \mathbf{1} \neq 0$.
		\item For each $S$, let $v = \frac{1}{\mathbf{1}\T S^{-1} \mathbf{1}}$, $(\mathbf{x}')\T = v \mathbf{1}\T S^{-1}$, and $\mathbf{y}' = v S^{-1} \mathbf{1}$.
		\item Pad $\mathbf{x}'$ and $\mathbf{y}'$ with $0$s to create $\mathbf{x}$ and $\mathbf{y}$.
		\item If either $\mathbf{x}$ or $\mathbf{y}$ has a negative component, reject the $S$ that created them.
		\item If $\mathbf{x}\T A \geq v \mathbf{1}\T$ and $A \mathbf{y} \leq v \mathbf{1}$, then $(\mathbf{x}, \mathbf{y}, v)$ is an extreme optimal solution to $A$.
		
	\end{enumerate}
	
\end{Theorem}



\begin{Proposition}
	
	If $A$ is square and completely mixed, then $A$ is invertible, since the only possible submatrix is $A$ itself and all matrix games have at least one solution.
	
\end{Proposition}





\begin{center}
	\vspace{.25in}
	\noindent\rule{.75\linewidth}{0.4pt}
	\vspace{.25in}
	
	\section{Linear Programming}
	
	\vspace{.1in}
\end{center}



\begin{Def}
	
	A \textbf{linear programming problem} is an optimization problem, where the goal is to maximize or minimize a linear function subject to certain constraints.
	
\end{Def}



\begin{Def}
	
	The \textbf{standard maximization linear program} is $
	\begin{cases}
	\max & \mathbf{c}\T \mathbf{y}\\
	\Sub & A \mathbf{y} \leq \mathbf{b}
	\end{cases}.
	$
	
	The \textbf{standard minimization linear program} is $
	\begin{cases}
	\min & \mathbf{x}\T \mathbf{b}\\
	\Sub & \mathbf{x}\T A \geq \mathbf{c}\T
	\end{cases}.
	$
	
\end{Def}



\begin{Theorem}
	
	\textbf{(The Simplex Algorithm)} To solve $
	\begin{cases}
	\max & \mathbf{c}\T \mathbf{y}\\
	\Sub & A \mathbf{y} \leq \mathbf{b}
	\end{cases}:
	$
	
	\begin{enumerate}
		
		\item Create the initial tableau:
		
		$$
		\begin{array}{c|ccc|ccc|c}
		 & y_1 & \cdots & y_m & x_1 & \cdots & x_n & \\
		 \hline
		 x_1 & & & & & & & b_1\\
		 \vdots & & A & & & I & & \vdots\\
		 x_n & & & & & & & b_n\\
		 \hline
	   	 & -c_1 & \cdots & -c_m & 0 & \cdots & 0 & 0
		
		\end{array}
		$$
		
		\item Find the column with the smallest entry in the bottom row and denote it column $j$. If that minimum value is nonnegative, stop.
		
		\item Find row $i$ such that $a_{ij} > 0$ and (the last entry in row $i$)/$a_{ij}$ is maximized but nonnegative.
		
		\item Use elementary row operations to place a $1$ in position $ij$ and $0$s in the rest of column $j$.
		
		\item Repeat steps 2--5.
		
	\end{enumerate}
	
\end{Theorem}



\begin{Def}
	
	The \textbf{dual linear program} to $
	\begin{cases}
	\max & \mathbf{c}\T \mathbf{y}\\
	\Sub & A \mathbf{y} \leq \mathbf{b}
	\end{cases}$ is $
	\begin{cases}
	\min & \mathbf{x}\T \mathbf{b}\\
	\Sub & \mathbf{x}\T A \geq \mathbf{c}\T
	\end{cases}.$\\
	
	Note that since every linear program can be written as a standard maximum, the definition extends to all linear programs.
	
\end{Def}



\begin{Proposition}
	
	If $\mathbf{x}$ and $\mathbf{y}$ satisfy $A\mathbf{y} \leq \mathbf{b}$ and $\mathbf{x}\T A \geq \mathbf{c}\T$, then $\mathbf{c}\T \mathbf{y} \leq \mathbf{x}\T \mathbf{b}$.
	
	\begin{Proof}
		%
		We have $\mathbf{c}\T \mathbf{y} \leq \mathbf{x}\T A \mathbf{y} \leq \mathbf{x}\T \mathbf{b}$.
		
	\end{Proof}
	
\end{Proposition}



\begin{Theorem}
	
	If $\mathbf{y}$ and $\mathbf{x}$ satisfy the conditions of a linear program and its dual, respectively, and $\mathbf{c}\T \mathbf{y} = \mathbf{x}\T \mathbf{b}$, then $\mathbf{y}$ and $\mathbf{x}$ are solutions to the linear program and its dual.
	
	\begin{Proof}
		%
		We want to maximize $\mathbf{c}\T \mathbf{y}$ and $\mathbf{x}\T \mathbf{b}$. But since $\mathbf{c}\T \mathbf{y} = \mathbf{x}\T \textbf{b}$, the previous result tells us that $\mathbf{c}\T \mathbf{y}$ cannot be any larger and $\mathbf{x}\T \mathbf{b}$ cannot be any smaller. Thus $\mathbf{y}$ and $\mathbf{x}$ are solutions.
		
	\end{Proof}
	
\end{Theorem}



\begin{Theorem}
	
	The Simplex Method always gives an $\mathbf{x}$ and $\mathbf{y}$ such that $\mathbf{c}\T \mathbf{y} = \mathbf{x}\T \textbf{b}$, so it can solve all linear programs.
	
\end{Theorem}




\begin{Theorem}
	
	Every matrix game can be solved with a linear program.
	
	\begin{Proof}
		%
		Let $A$ be a matrix game. The column player wants a strategy $\mathbf{q}$ such that $\mathbf{1}\T \mathbf{q} = 1$, $\mathbf{q} \geq \mathbf{0}$, and $A \mathbf{q} \leq v \mathbf{1}$. Let $\mathbf{y} = \frac{\mathbf{q}}{v}$. Then we have $
		\begin{cases}
		\min & v\\
		\Sub & A \mathbf{y} \leq \mathbf{1}
		\end{cases}$, or, equivalently, $
		\begin{cases}
		\max & \mathbf{1}\T \mathbf{y}\\
		\Sub & A \mathbf{y} \leq \mathbf{b}
		\end{cases}$. Similarly, the row player wants a strategy $\mathbf{p}$ such that $\mathbf{p}\T \mathbf{1} = 1$, $\mathbf{p} \geq \mathbf{0}$, and $\mathbf{p}\T A \geq v \mathbf{1}\T$, so if $\mathbf{x} = \frac{\mathbf{p}}{v}$, we have $
		\begin{cases}
		\min & \mathbf{x}\T \mathbf{1}\\
		\Sub & \mathbf{x}\T A \geq \mathbf{1}\T
		\end{cases}$, the dual program.
		
	\end{Proof}
	
\end{Theorem}



\begin{Theorem}
	
	\textbf{(Using the Simplex Algorithm to solve Matrix Games)} Let $A$ be a matrix game.
	
	\begin{enumerate}
		
		\item Ensure $v \geq 0$ (this can be done without loss of generality by adding a large enough constant value to every entry of $A$.)
		
		\item Solve $
		\begin{cases}
		\max & \mathbf{1}\T \mathbf{y}\\
		\Sub & A \mathbf{y} \leq \mathbf{b}
		\end{cases}$. Then the solution, $\mathbf{y}$, and the solution to the dual, $\mathbf{x}$, are \textit{proportional} to an optimal solution.
		
	\end{enumerate}
	
\end{Theorem}





\begin{center}
	\vspace{.25in}
	\noindent\rule{.75\linewidth}{0.4pt}
	\vspace{.25in}
	
	\section{Interval Games}
	
	\vspace{.1in}
\end{center}



\begin{Def}
	
	Let $I_1, I_2 \subseteq \mathbb{R}$ be intervals. An \textbf{interval game} is a function $A : I_1 \times I_2 \longrightarrow \mathbb{R}$. To play, players $x$ and $y$ independently select $x \in I_1$ and $y \in I_2$, and the payoffs are $A(x, y)$ and $-A(x, y)$, respectively. 
	
\end{Def}



\begin{Def}
	
	An interval game $A$ has a \textbf{saddle point} at $(x_0, y_0)$ if $\frac{\partial}{\partial x}[A]\vline _{x=x_0} = 0$, $\frac{\partial}{\partial y}[A]\vline _{y=y_0} = 0$, $\frac{\partial^2}{\partial x^2}[A]\vline _{x=x_0} < 0$, and $\frac{\partial^2}{\partial y^2}[A]\vline _{y=y_0} > 0$.
	
\end{Def}



\begin{Def}
	
	Let $X$ be a random variable. The \textbf{cumulative distribution function} (cdf) $F$ for $X$ is $F(x) = \Pr(X \leq x)$. Notice that $\lim\limits_{x \to -\infty} F(x) = 0$, $\lim\limits_{x \to \infty} F(x) = 1$, $F$ is nondecreasing, and $\Pr(x \in (a,b]) = F(b) - F(a)$.
	
\end{Def}



\begin{Proposition}
	
	If $x$ uses the strategy $F(x)$ and $y$ uses $y_0$, then the expected payoff is\\
	$\int_{-\infty}^{\infty} A(x, y_0) F'(x)\ \textnormal{d}x$.
	
\end{Proposition}



\begin{Def}
	
	Let $A$ be an interval game. A \textbf{solution} to $A$ is a tuple $(F, G, v)$, where $F(x)$ and $G(y)$ are cdfs such that $F'$ and $G'$ exist on their intervals, $\int_{I_1} A(x, y) F'(x)\ \textnormal{d}x \geq v$, and $\int_{I_2} A(x, y) G'(y)\ \textnormal{d}y \leq v$.
	
\end{Def}





\begin{center}
	\vspace{.25in}
	\noindent\rule{.75\linewidth}{0.4pt}
	\vspace{.25in}
	
	\section{Utility Theory}
	
	\vspace{.1in}
\end{center}



\begin{Def}
	
	Let $A$ be a set of possible outcomes. A \textbf{preference} on $A$ is a relation $\preceq$ such that
	
	\begin{enumerate}
		
		\item For all $a, b \in A$, either $a \preceq b$ or $b \preceq a$.
		
		\item For all $a, b, c \in A$, if $a \preceq b$ and $b \preceq c$, then $a \preceq c$.
		
	\end{enumerate}
	
\end{Def}



\begin{Def}
	
	A \textbf{utility function} is a function $u : A \longrightarrow \mathbb{R}$ such that $u(a) \leq u(b)$ whenever $a \preceq b$. Note that all payoffs are utilities (the utility function is the entry of the matrix) and that utilities are scale-invariant, so $u(x)$ and $au(x) + b$ record the same information.
	
\end{Def}



\begin{Axiom}
	
	Let $a, b, c \in A$. If $a \prec b$, then there is a $p \in (0,1)$ such that $a \prec pb + (1-p)c$.
	
\end{Axiom}



\begin{Theorem}
	
	\textbf{(Turing a Preference into a Utility Function)} Find the least- and most-preferred outcomes, say $a$ and $c$, and let $u(a) = 0$ and $u(c) = 1$. Then consider lotteries. For example, which is preferred: a $\frac{1}{2} a \frac{1}{2} c$ lottery, or a guaranteed $b$? The answer determines whether $u(b) \geq \frac{1}{2}$ or $u(b) \leq \frac{1}{2}$. Repeat to create a convergent sequence for $u(b)$, then for all $b \in A$.
	
\end{Theorem}





\begin{center}
	\vspace{.25in}
	\noindent\rule{.75\linewidth}{0.4pt}
	\vspace{.25in}
	
	\section{Nonzero-Sum Games}
	
	\vspace{.1in}
\end{center}



\begin{Def}
	
	A \textbf{2-player, nonzero-sum matrix game} is a bimatrix.
	
\end{Def}



\begin{Example}
	%
	$$
	\begin{bmatrix}
	
	(-10, -10) & (5, 2)\\
	(2, 5) & (1, 1)
	
	\end{bmatrix}
	$$
	
\end{Example}



\begin{Def}
	
	Let $P_i(s_1, ..., s_n)$ be the payoff to player $i$ when player $j$ does $s_j$ for all $j$. An \textbf{equilibrium point} is a tuple $(s_1, ..., s_n)$ such that $P_i(s_1, ..., s_n) \geq P_i(s_1, ..., \hat{s_i}, ..., s_n)$ for all strategies $\hat{s_i}$ and for all $i$. In other words, if each player knows what every other player intends to do and no one changes their own strategy, the outcome is an equilibrium point.
	
\end{Def}



\begin{Theorem}
	
	\textbf{(Nash, 1949)} All finite games have an equilibrium point.
	
\end{Theorem}



\begin{Theorem}
	
	\textbf{(Solving $2 \times 2$ Bimatrix Games for all Equilibria)} Let $A$ be a bimatrix.
	
	\begin{enumerate}
		
		\item Check if any entry is an equilibrium.
		
		\item Equalize the opponent's expectations by letting $\mathbf{x} = [p\ \ \ 1-p]\T$ and setting the two coordinates of $\mathbf{x}\T A_2$ equal to solve for $p$, where $A_2$ is the matrix formed of player $2$'s payoffs. Similarly, let $\mathbf{y} = [q\ \ \ 1-q]\T$ and set the two coordinates of $A_1 \mathbf{y}$ equal to solve for $q$. Then $(\mathbf{x}, \mathbf{y})$ is an equilibrium point.
		
	\end{enumerate}
	
\end{Theorem}



\begin{Def}
	
	An outcome of a bimatrix is \textbf{Pareto-optimal} if no other outcome is better for one player and not worse for the others.
	
\end{Def}



\begin{Theorem}
	
	If every equilibrium point of a bimatrix game is Pareto-optimal and has the same value, then the game has a solution.
	
\end{Theorem}



\begin{Example}
	%
	\textbf{(The Prisoner's Dilemma)} Consider the bimatrix game
	
	$$
	\begin{bmatrix}
	
	(R, R) & (S, T)\\
	(T, S) & (U, U)
	
	\end{bmatrix}\textnormal{,}
	$$
	
	where $T > R > U > S$ and $R > \frac{S+T}{2}$. For instance,
	
	$$
	\begin{bmatrix}
	
	(0, 0) & (-2, 1)\\
	(1, -2) & (-1, -1)
	
	\end{bmatrix}\textnormal{.}
	$$
	
	The game is symmetric and the only equilibrium point is $(U, U)$, but it is not Pareto-optimal.
	
\end{Example}



\begin{Def}
	
	Let $P_1(s, t)$ be the payoff to player $1$ when strategy $s$ is used by player $1$ and strategy $t$ by player 2. An \textbf{evolutionarily stable strategy} is a strategy $S$ such that $(S, S)$ is an equilibrium (it is stable) and $P_1(S, t) > P_1(t, t)$ for all $t \neq S$ (strategies could evolve to it, since it gives an advantage over every other strategy).
	
\end{Def}



\begin{Example}
	%
	Consider the bimatrix game
	
	$$
	\begin{blockarray}{ccc}
		& A & B\\
		\begin{block}{c[cc]}
			A & (-4, -4) & (4, 0)\\
			B & (0, 4) & (2, 2)\\
		\end{block}
	\end{blockarray}\textnormal{.}
	$$
	
	It can be shown that there are three equilibria: $(A, B)$, $(B, A)$, and $(\frac{1}{3} A + \frac{2}{3} B, \frac{1}{3} A + \frac{2}{3} B)$. The first two cannot be ESSs, since they are not symmetric. The third is, however, since
	
	$$
	\begin{bmatrix}
	\frac{1}{3} & \frac{2}{3}
	\end{bmatrix} \begin{bmatrix}
	-4 & 4\\
	0 & 2
	\end{bmatrix} \begin{bmatrix}
	p\\
	1 - p
	\end{bmatrix} > \begin{bmatrix}
	p & 1 - p
	\end{bmatrix} \begin{bmatrix}
	-4 & 4\\
	0 & 2
	\end{bmatrix} \begin{bmatrix}
	p\\
	1 - p
	\end{bmatrix}
	$$
	
	for all $p \neq \frac{1}{3}$, since this reduces to $\frac{8}{3} - 4p > 2 - 6p^2$, which can be shown to be true for all $p \in [0, 1] \setminus \{\frac{1}{3}\}$. 
	
\end{Example}





\begin{center}
	\vspace{.25in}
	\noindent\rule{.75\linewidth}{0.4pt}
	\vspace{.25in}
	
	\section{Arbitration}
	
	\vspace{.1in}
\end{center}



\begin{Def}
	
	A player's \textbf{prudential strategy} is the optimal strategy when treating their own payoffs as being zero-sum. A player's \textbf{security level} is the value of this zero-sum game.
	
\end{Def}



\begin{Axiom}
	
	A \textbf{fair outcome} satisfies the following axioms.
	
	\begin{enumerate}
		
		\item A fair outcome is Pareto-optimal and above both player's security levels.
		
		\item If utility functions are rescaled, then a fair outcome is equally rescaled.
		
		\item If a game is symmetric, then so is any fair outcome for that game.
		
		\item If the status quo is in a convex set $C_1$, $C_1 \subseteq C_2$, and a fair outcome for $C_2$ is also in $C_1$, then the same outcome is fair for $C_1$.
		
	\end{enumerate}
	
	Here, the \textbf{status quo} is the outcome achieved when the players cannot agree.
	
\end{Axiom}



\begin{Theorem}
	
	\textbf{(Nash, 1950)} The unique outcome that satisfies the fairness axioms is the $(x, y)$ pair on the upper-right boundary of the convex set of outcomes that maximizes $(x - x_0)(y - y_0)$, where $(x_0, y_0)$ is the status quo.
	
	\begin{Proof}
		%
		By axiom 2, let $(x_0, y_0)$ have utility $(0, 0)$ and the $(x, y)$ that maximizes $(x - x_0)(y - y_0)$ have utility $(1, 1)$. Since $xy = 1$, the convex set $C$ lies below $y = \frac{1}{x}$. Enclose $C$ in a symmetric set $D$. By axiom 3, the fair outcome for $D$ must lie on the line $y = x$, so it must be $(1, 1)$ by axiom 1. Then by axiom 4, the fair outcome for $C$ is also $(1, 1)$.
		
	\end{Proof}
	
\end{Theorem}





\begin{center}
	\vspace{.25in}
	\noindent\rule{.75\linewidth}{0.4pt}
	\vspace{.25in}
	
	\section{\textit{n}-Player Games}
	
	\vspace{.1in}
\end{center}



\begin{Def}
	
	An \textbf{$n$-player game in characteristic function form} is a function $\nu : \mathcal{P}(p_1, ..., p_n) \longrightarrow \mathbb{R}$, defined by $\nu(S) = (\textnormal{the utility that coalition } S \textnormal{ can earn})$. Notice that is completely unspecified how a coalition should splitits earnings among itself.
	
\end{Def}



\begin{Axiom}
	
	A distribution of earnings $(x_1, ..., x_n)$ is \textbf{fair} if
	
	\begin{enumerate}
		
		\item For all $i$, $\nu(\{i\}) \leq x_i$ (every player earns at least as much than they could on their own).
		
		\item $x_1 + \cdots + x_n = \nu(S)$ (all the earnings are distributed).
		
		\item If players $i$ and $j$ are identical, then $x_i = x_j$ (equal players earn equal amounts).
		
		\item If $\nu(S \setminus \{i\}) = \nu(S)$ for all coalitions $S$, then $x_i = 0$ (noncontributing players earn nothing).
		
		\item If $(x_1, ..., x_n)$ is fair under $\nu$ and $(y_1, ..., y_n)$ is fair under $\mu$, then $(x_1 + y_1, ..., x_n + y_n)$ is fair under $\nu + \mu$ (different kinds of earnings can be counted together).
		
	\end{enumerate}
	
\end{Axiom}



\begin{Theorem}
	
	The unique $(x_1, ..., x_n)$ satisfying the previous axioms is given by
	
	$$
	x_i = \frac{1}{n!} \scaleto{\sum\limits_{S \subseteq \{1, ..., n\}}}{7ex} \hspace{-1.5em} (|S| - 1)! (n - |S|)! (\nu(S) - \nu(S \setminus \{i\}))\textnormal{.}
	$$
	
	\begin{Proof}
		%
		The purposes of the various components:
		
		$\frac{1}{n!} \sum\limits_{S \subseteq \{1, ..., n\}}$: average over all possible coalitions.\\
		
		$(|S| - 1)!$ the ways a coalition can form before player $i$ joins.\\
		
		$(n - |S|)!$ the ways a coalition can be completed after player $i$ joins.\\
		
		$(\nu(S) - \nu(S \setminus \{i\}))$: the utility increase due to player $i$.
		
	\end{Proof}
	
\end{Theorem}



\begin{Def}
	
	Let $s_i$ be the number of swing votes that player $i$ has (the number of coalitions that would move from losing to winning by player $i$ joining). The \textbf{Banzhaf power index} for player $i$ is $\frac{s_i}{s_1 + \cdots + s_n}$.
	
\end{Def}





\end{document}