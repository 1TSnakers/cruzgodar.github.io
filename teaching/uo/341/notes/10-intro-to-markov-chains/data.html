<header><div id="logo"><a href="/home/" tabindex="-1"><img src="/graphics/general-icons/logo.png" alt="Logo" tabindex="1"></img></a></div><div style="height: 20px"></div><h1 class="heading-text">Section 10: Intro to Markov Chains</h1></header><main><section><div class="text-buttons nav-buttons"><div class="focus-on-child tabindex="1"><button class="text-button linked-text-button previous-nav-button" type="button" tabindex="-1">Previous</button></div><div class="focus-on-child" tabindex="1"><button class="text-button linked-text-button home-nav-button" type="button" tabindex="-1">Home</button></div><div class="focus-on-child" tabindex="1"><button class="text-button linked-text-button next-nav-button" type="button" tabindex="-1">Next</button></div></div><p class="body-text">With so much theory developed, let&#x2019;s take these last two sections to explore some of the most important applications of linear algebra. One of the most ubiquitous in modern technology is in graphics, where the function that maps any triangle in 3D space to its image on a fixed 2D screen is a linear map (called a <em>projection map</em>). With very few exceptions, this is the foundation of how every 3D game is implemented.</p><p class="body-text">Our first application will be to a different area, though, closer to statistics. Let&#x2019;s say that we have a collection of <strong>states</strong> <span class="tex-holder inline-math" data-source-tex="x_1, ..., x_n">$x_1, ..., x_n$</span>. These are states of matter or being &mdash; for example, in <a href="https://www.youtube.com/watch?v=LL3kVtc-4vY">Belousov-Zhabotinsky reaction</a>, <span class="tex-holder inline-math" data-source-tex="x_1">$x_1$</span> might represent a molecule of malonic acid and <span class="tex-holder inline-math" data-source-tex="x_2">$x_2$</span> a molecule of potassium bromate (in reality, we&#x2019;d need many more variables for the intermediate states in the reaction).This system, and many like it, fall into a particular class that lend themselves extremely well to linear algebra:</p><div class="notes-def notes-environment"><p class="body-text"</p><span class="notes-def-title">Definition: Markov chain</span></p><p class="body-text">Let <span class="tex-holder inline-math" data-source-tex="x_1, ..., x_n">$x_1, ..., x_n$</span> be a collection of states and let <span class="tex-holder inline-math" data-source-tex="\vec{x} \in \operatorname{span}\{x_1, ..., x_n\}">$\vec{x} \in \operatorname{span}\{x_1, ..., x_n\}$</span> be a vector whose coefficients sum to <span class="tex-holder inline-math" data-source-tex="1">$1$</span> &mdash; we think of <span class="tex-holder inline-math" data-source-tex="x">$x$</span> as representing the <em>proportion</em> of the system in each state, or equivalently the probabilities of a randomly-chosen element being in a given state. If the system evolves over time as a function <span class="tex-holder inline-math" data-source-tex="\vec{x}(t)">$\vec{x}(t)$</span>, but the value of <span class="tex-holder inline-math" data-source-tex="\vec{x}(t)">$\vec{x}(t)$</span> is a linear function of <span class="tex-holder inline-math" data-source-tex="\vec{x}(t - 1)">$\vec{x}(t - 1)$</span> and no other factors, then we call <span class="tex-holder inline-math" data-source-tex="\vec{x}(t)">$\vec{x}(t)$</span> a <strong>Markov chain</strong>.</p></div><p class="body-text">A Markov chain is defined by a linear map <span class="tex-holder inline-math" data-source-tex="P : \mathbb{R}^n \to \mathbb{R}^n">$P : \mathbb{R}^n \to \mathbb{R}^n$</span> such that</p><p class="body-text" style="text-align: center"><span class="tex-holder" style="padding: 8px" data-source-tex="$$[NEWLINE][TAB]P[\vec{x}(t)]_\mathcal{E} = [\vec{x}(t + 1)]_\mathcal{E},[NEWLINE]$$">$$\begin{align*}P[\vec{x}(t)]_\mathcal{E} = [\vec{x}(t + 1)]_\mathcal{E},\end{align*}$$</span></p><p class="body-text">where <span class="tex-holder inline-math" data-source-tex="\mathcal{E} = \{x_1, ..., x_n\}">$\mathcal{E} = \{x_1, ..., x_n\}$</span> is the basis consisting of the different states. There is a shocking amount of information we can extract from just this description &mdash; let&#x2019;s see it in action.</p><div class="notes-ex notes-environment"><p class="body-text"</p><span class="notes-ex-title">Example: Markov chain</span></p><p class="body-text">You make the questionable decision to open a casino based solely on coin flipping. For a 4 dollar fee, a participant can flip a coin 3 times. If they get <span class="tex-holder inline-math" data-source-tex="k">$k$</span> heads, then they receive a payout of <span class="tex-holder inline-math" data-source-tex="2^k">$2^k$</span> dollars. Write the process as a Markov chain and find the probabilities of every different payout. Do you gain or lose money on average from people playing this game?</p></div><div class="text-buttons nav-buttons"><div class="focus-on-child tabindex="1"><button class="text-button linked-text-button previous-nav-button" type="button" tabindex="-1">Previous</button></div><div class="focus-on-child" tabindex="1"><button class="text-button linked-text-button home-nav-button" type="button" tabindex="-1">Home</button></div><div class="focus-on-child" tabindex="1"><button class="text-button linked-text-button next-nav-button" type="button" tabindex="-1">Next</button></div></div></section></main>